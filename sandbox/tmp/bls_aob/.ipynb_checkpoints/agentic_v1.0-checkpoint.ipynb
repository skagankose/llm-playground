{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bccbb57-90f8-4eed-9efa-69bd73971d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import END\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Annotated\n",
    "\n",
    "import operator\n",
    "import os\n",
    "import getpass\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420cc66d-e128-4f10-b6a2-ef8ba40e00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "local_llm = \"llama3.2:3B\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "llm_json_mode = ChatOllama(model=local_llm, temperature=0, format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659c471b-52f0-42a0-8fce-9ba53f198835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "        \n",
    "# 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\n",
    "# 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\n",
    "# _set_env(\"LANGSMITH_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=\"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\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"local-agentic_v2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ff601a9-2285-4ea5-bbfb-a23a125e9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _set_env(\"TAVILY_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a17b4-2e2c-4061-8c6b-da897b4dd649",
   "metadata": {},
   "source": [
    "## RETRIEVER - Create Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4862ec64-36f8-46bb-a5b4-54b803f517f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load libllamamodel-mainline-cuda.so: dlopen: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "Failed to load libllamamodel-mainline-cuda-avxonly.so: dlopen: libcudart.so.11.0: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "# Load documents\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\"),\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd696637-af31-46db-aca1-dc0dcdaeb108",
   "metadata": {},
   "source": [
    "## ROUTER - Categorize User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2765a88b-2c1c-47a2-8312-cd1c99b82aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasource': 'websearch'} {'datasource': 'websearch'} {'datasource': 'vectorstore'}\n"
     ]
    }
   ],
   "source": [
    "router_instructions = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "\n",
    "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
    "\n",
    "Use the vectorstore for questions on these topics. For all else, and especially for current events, use web-search.\n",
    "\n",
    "Return JSON with single key, datasource, that is 'websearch' or 'vectorstore' depending on the question.\"\"\"\n",
    "\n",
    "q_1 = \"Who is favored to win the NFC Championship game in the 2024 season?\"\n",
    "test_web_search = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=router_instructions)] + [HumanMessage(content=q_1 )]\n",
    ")\n",
    "q_2 = \"What are the models released today for llama3.2?\"\n",
    "test_web_search_2 = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=router_instructions)] + [HumanMessage(content=q_2)]\n",
    ")\n",
    "q_3 = \"What are the types of agent memory?\"\n",
    "test_vector_store = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=router_instructions)] + [HumanMessage(content=q_3)]\n",
    ")\n",
    "\n",
    "print(\n",
    "    json.loads(test_web_search.content),\n",
    "    json.loads(test_web_search_2.content),\n",
    "    json.loads(test_vector_store.content),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38791f06-566e-4b8e-937a-d630470db7f9",
   "metadata": {},
   "source": [
    "## GRADER - Check Relevancy of Retrieved Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0915aa97-8f57-42f9-a242-cc30123215c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_score': 'yes'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doc grader instructions\n",
    "doc_grader_instructions = \"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "\n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "doc_grader_prompt = \"\"\"Here is the retrieved document: \\n\\n {document} \\n\\n Here is the user question: \\n\\n {question}. \n",
    "\n",
    "This carefully and objectively assess whether the document contains at least some information that is relevant to the question.\n",
    "\n",
    "Return JSON with single key, binary_score, that is 'yes' or 'no' score to indicate whether the document contains at least some information that is relevant to the question.\"\"\"\n",
    "\n",
    "# Test\n",
    "question = \"What is Chain of thought prompting?\"\n",
    "# question = \"What is the presidency called in Ottomans?\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "doc_grader_prompt_formatted = doc_grader_prompt.format(\n",
    "    document=doc_txt, question=question\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=doc_grader_instructions)]\n",
    "    + [HumanMessage(content=doc_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90784509-7431-453c-be84-61dfb9b1dd2e",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da94a09-3823-463f-a582-b261d423b8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain of Thought prompting is a technique used in large language models to elicit reasoning and provide explanations for their responses. It involves providing prompts that guide the model to generate a sequence of related thoughts, allowing it to demonstrate its understanding and reasoning capabilities. This technique has been shown to improve the performance of language models on tasks requiring in-context learning and multi-step reasoning.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "rag_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "\n",
    "Here is the context to use to answer the question:\n",
    "\n",
    "{context} \n",
    "\n",
    "Think carefully about the above context. \n",
    "\n",
    "Now, review the user question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Provide an answer to this questions using only the above context. \n",
    "\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Test\n",
    "docs = retriever.invoke(question)\n",
    "docs_txt = format_docs(docs)\n",
    "rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
    "generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "print(generation.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15777cbe-3eaf-4a0c-b55c-e924c872a39c",
   "metadata": {},
   "source": [
    "## GRADER - Check if Hallucination Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34a1447d-352b-4d15-987a-c9589bd4ba14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_score': 'yes',\n",
       " 'explanation': 'The STUDENT ANSWER is grounded in the facts as it correctly describes Chain of Thought prompting as a technique used in large language models to elicit reasoning and provide explanations for their responses.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hallucination grader instructions\n",
    "hallucination_grader_instructions = \"\"\"\n",
    "\n",
    "You are a teacher grading a quiz. \n",
    "\n",
    "You will be given FACTS and a STUDENT ANSWER. \n",
    "\n",
    "Here is the grade criteria to follow:\n",
    "\n",
    "(1) Ensure the STUDENT ANSWER is grounded in the FACTS. \n",
    "\n",
    "(2) Ensure the STUDENT ANSWER does not contain \"hallucinated\" information outside the scope of the FACTS.\n",
    "\n",
    "Score:\n",
    "\n",
    "A score of yes means that the student's answer meets all of the criteria. This is the highest (best) score. \n",
    "\n",
    "A score of no means that the student's answer does not meet all of the criteria. This is the lowest possible score you can give.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
    "\n",
    "Avoid simply stating the correct answer at the outset.\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "hallucination_grader_prompt = \"\"\"FACTS: \\n\\n {documents} \\n\\n STUDENT ANSWER: {generation}. \n",
    "\n",
    "Return JSON with two two keys, binary_score is 'yes' or 'no' score to indicate whether the STUDENT ANSWER is grounded in the FACTS. \n",
    "\n",
    "And a key, explanation, that contains an explanation of the score.\"\"\"\n",
    "\n",
    "# Test using documents and generation from above\n",
    "hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(\n",
    "    documents=docs_txt, generation=generation.content\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=hallucination_grader_instructions)]\n",
    "    + [HumanMessage(content=hallucination_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5305d99-d5d9-4260-a741-362cc0a22a74",
   "metadata": {},
   "source": [
    "## GRADER - Check if the Final Answer is Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdfc90a0-a6d4-4b49-b035-4699b51e4158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_score': 'yes',\n",
       " 'explanation': \"The student's answer helps to answer the question by providing specific details about the vision models released as part of Llama 3.2, including their names and availability on Azure AI Model Catalog. The answer also provides context about the models' capabilities and how they compare to other multimodal AI models. While the answer contains some extraneous information (e.g., the comparison to Claude 3 Haiku and GPT-4o mini), it still meets all of the criteria for answering the question, which is to identify the vision models released as part of Llama 3.2.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer grader instructions\n",
    "answer_grader_instructions = \"\"\"You are a teacher grading a quiz. \n",
    "\n",
    "You will be given a QUESTION and a STUDENT ANSWER. \n",
    "\n",
    "Here is the grade criteria to follow:\n",
    "\n",
    "(1) The STUDENT ANSWER helps to answer the QUESTION\n",
    "\n",
    "Score:\n",
    "\n",
    "A score of yes means that the student's answer meets all of the criteria. This is the highest (best) score. \n",
    "\n",
    "The student can receive a score of yes if the answer contains extra information that is not explicitly asked for in the question.\n",
    "\n",
    "A score of no means that the student's answer does not meet all of the criteria. This is the lowest possible score you can give.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
    "\n",
    "Avoid simply stating the correct answer at the outset.\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "answer_grader_prompt = \"\"\"QUESTION: \\n\\n {question} \\n\\n STUDENT ANSWER: {generation}. \n",
    "\n",
    "Return JSON with two two keys, binary_score is 'yes' or 'no' score to indicate whether the STUDENT ANSWER meets the criteria. And a key, explanation, that contains an explanation of the score.\"\"\"\n",
    "\n",
    "# Test\n",
    "question = \"What are the vision models released today as part of Llama 3.2?\"\n",
    "answer = \"The Llama 3.2 models released today include two vision models: Llama 3.2 11B Vision Instruct and Llama 3.2 90B Vision Instruct, which are available on Azure AI Model Catalog via managed compute. These models are part of Meta's first foray into multimodal AI and rival closed models like Anthropic's Claude 3 Haiku and OpenAI's GPT-4o mini in visual reasoning. They replace the older text-only Llama 3.1 models.\"\n",
    "\n",
    "# Test using question and generation from above\n",
    "answer_grader_prompt_formatted = answer_grader_prompt.format(\n",
    "    question=question, generation=answer\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=answer_grader_instructions)]\n",
    "    + [HumanMessage(content=answer_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba082072-ded2-4883-95f9-1bc5fc1dcfc5",
   "metadata": {},
   "source": [
    "## Web-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a9f61d3-a5d2-4413-87ce-5265a60347bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b915bc-6e79-45b9-9683-5301cb062afe",
   "metadata": {},
   "source": [
    "# LANGRAPH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0b6200-6d20-45b6-bc2e-95454e27471c",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ff3e743-e93d-4979-8fc3-81327f61934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Graph state is a dictionary that contains information we want to propagate to, and modify in, each graph node.\n",
    "    \"\"\"\n",
    "\n",
    "    question: str  # User question\n",
    "    generation: str  # LLM generation\n",
    "    web_search: str  # Binary decision to run web search\n",
    "    max_retries: int  # Max number of retries for answer generation\n",
    "    answers: int  # Number of answers generated\n",
    "    loop_step: Annotated[int, operator.add]\n",
    "    documents: List[str]  # List of retrieved documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9ff13-3189-4645-80b9-56672f845486",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5200a33b-2e09-42e8-99ac-9338b7789fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Write retrieved documents to documents key in state\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    loop_step = state.get(\"loop_step\", 0)\n",
    "\n",
    "    # RAG generation\n",
    "    docs_txt = format_docs(documents)\n",
    "    rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
    "    generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "    return {\"generation\": generation, \"loop_step\": loop_step + 1}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        doc_grader_prompt_formatted = doc_grader_prompt.format(\n",
    "            document=d.page_content, question=question\n",
    "        )\n",
    "        result = llm_json_mode.invoke(\n",
    "            [SystemMessage(content=doc_grader_instructions)]\n",
    "            + [HumanMessage(content=doc_grader_prompt_formatted)]\n",
    "        )\n",
    "        grade = json.loads(result.content)[\"binary_score\"]\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            # We do not include the document in filtered_docs\n",
    "            # We set a flag to indicate that we want to run web search\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"web_search\": web_search}\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "    return {\"documents\": documents}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013bd432-9bc5-419b-8418-683cf0946c4f",
   "metadata": {},
   "source": [
    "## Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "608a7bc2-f10e-42cb-b460-328b44acf814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    route_question = llm_json_mode.invoke(\n",
    "        [SystemMessage(content=router_instructions)]\n",
    "        + [HumanMessage(content=state[\"question\"])]\n",
    "    )\n",
    "    source = json.loads(route_question.content)[\"datasource\"]\n",
    "    if source == \"websearch\":\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    elif source == \"vectorstore\":\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: NOT ALL DOCUMENTS ARE RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\"\n",
    "        )\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "    max_retries = state.get(\"max_retries\", 3)  # Default to 3 if not provided\n",
    "\n",
    "    hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(\n",
    "        documents=format_docs(documents), generation=generation.content\n",
    "    )\n",
    "    result = llm_json_mode.invoke(\n",
    "        [SystemMessage(content=hallucination_grader_instructions)]\n",
    "        + [HumanMessage(content=hallucination_grader_prompt_formatted)]\n",
    "    )\n",
    "    grade = json.loads(result.content)[\"binary_score\"]\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        # Test using question and generation from above\n",
    "        answer_grader_prompt_formatted = answer_grader_prompt.format(\n",
    "            question=question, generation=generation.content\n",
    "        )\n",
    "        result = llm_json_mode.invoke(\n",
    "            [SystemMessage(content=answer_grader_instructions)]\n",
    "            + [HumanMessage(content=answer_grader_prompt_formatted)]\n",
    "        )\n",
    "        grade = json.loads(result.content)[\"binary_score\"]\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        elif state[\"loop_step\"] <= max_retries:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: MAX RETRIES REACHED---\")\n",
    "            return \"max retries\"\n",
    "    elif state[\"loop_step\"] <= max_retries:\n",
    "        print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n",
    "    else:\n",
    "        print(\"---DECISION: MAX RETRIES REACHED---\")\n",
    "        return \"max retries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375d25d-657c-4d0f-8247-db040afa730d",
   "metadata": {},
   "source": [
    "## FLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1442f2a6-022c-4f21-8c63-0b262edd166b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"websearch\", web_search)  # web search\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generate\n",
    "\n",
    "# Build graph\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"websearch\",\n",
    "        \"max retries\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e0a5210-f33a-439d-b483-d6359002aefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO RAG---\n",
      "{'question': 'How to make object detection using pytorch?', 'max_retries': 3, 'loop_step': 0}\n",
      "---RETRIEVE---\n",
      "{'question': 'How to make object detection using pytorch?', 'max_retries': 3, 'loop_step': 0, 'documents': [Document(metadata={'id': '73c71096-21dd-4cb6-a77f-fbc8531c5071', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\", 'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en'}, page_content=\"$$\\n\\\\arg\\\\min_{\\\\mathbf{t}} \\\\mathbb{E}_{\\\\mathbf{x}\\\\sim\\\\mathcal{D}} [\\\\mathcal{L}_\\\\text{adv}(\\\\tilde{y}, f([\\\\mathbf{t}; \\\\mathbf{x}]))]\\n$$\\n\\nThen let’s apply HotFlip to search for the most effective token based on the change in loss approximated by first-order Taylor expansion. We would convert the triggering tokens $\\\\mathbf{t}$ into their one-hot embedding representations, each vector of dimension size $d$, form $\\\\mathbf{e}$ and update the embedding of every trigger tokens to minimize the first-order Taylor expansion:\\n\\n$$\\n\\\\arg\\\\min_{\\\\mathbf{e}'_i \\\\in \\\\mathcal{V}} [\\\\mathbf{e}'_i - \\\\mathbf{e}_i]^\\\\top \\\\nabla_{\\\\mathbf{e}_i} \\\\mathcal{L}_\\\\text{adv}\\n$$\\n\\nwhere $\\\\mathcal{V}$ is the embedding matrix of all the tokens. $\\\\nabla_{\\\\mathbf{e}_i} \\\\mathcal{L}_\\\\text{adv}$ is the average gradient of the task loss over a batch around the current embedding of the $i$-th token in the adversarial triggering sequence $\\\\mathbf{t}$. We can brute-force the optimal $\\\\mathbf{e}’_i$ by a big dot product of size embedding of the entire vocabulary  $\\\\vert \\\\mathcal{V} \\\\vert$  $\\\\times$ the embedding dimension $d$. Matrix multiplication of this size is cheap and can be run in parallel.\\nAutoPrompt (Shin et al., 2020) utilizes the same gradient-based search strategy to find the most effective prompt template for a diverse set of tasks.\\nThe above token search method can be augmented with beam search. When looking for the optimal token embedding $\\\\mathbf{e}’_i$, we can pick top-$k$ candidates instead of a single one, searching from left to right and score each beam by $\\\\mathcal{L}_\\\\text{adv}$ on the current data batch.\\n\\nFig. 4. Illustration of how Universal Adversarial Triggers (UAT) works. (Image source: Wallace et al. 2019)\\nThe design of the loss $\\\\mathcal{L}_\\\\text{adv}$  for UAT is task-specific. Classification or reading comprehension relies on cross entropy. In their experiment, conditional text generation is configured to maximize the likelihood of a language model $p$ generating similar content to a set of bad outputs $\\\\mathcal{Y}_\\\\text{bad}$ given any user input:\\n\\n$$\\n\\\\mathcal{L}_\\\\text{adv} = \\\\mathbb{E}_{\\\\mathbf{y} \\\\sim \\\\mathcal{Y}_\\\\text{bad}, \\\\mathbf{x} \\\\sim \\\\mathcal{X}} \\\\sum_{i=1}^{\\\\vert \\\\mathcal{Y}_\\\\text{bad} \\\\vert} \\\\log\\\\big(1 - \\\\log(1 - p(y_i \\\\vert \\\\mathbf{t}, \\\\mathbf{x}, y_1, \\\\dots, y_{i-1}))\\\\big)\\n$$\\n\\nIt is impossible to exhaust the entire space of $\\\\mathcal{X}, \\\\mathcal{Y}_\\\\text{bad}$ in practice, but the paper got decent results by representing each set with a small number of examples. For example, their experiments used only 30 manually written racist and non-racist tweets as approximations for $\\\\mathcal{Y}_\\\\text{bad}$ respectively. They later found that a small number of examples for $\\\\mathcal{Y}_\\\\text{bad}$ and ignoring $\\\\mathcal{X}$ (i.e. no $\\\\mathbf{x}$ in the formula above) give good enough results.\"), Document(metadata={'id': '24207db7-f38f-4cbd-80e5-f8a862811f64', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\", 'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en'}, page_content='Explore: Sample from the model and examine the outputs. Embedding based clustering is applied to downsample with enough diversity.\\nEstablish: Humans judge the model outputs as good vs bad. Then a harmfulness classifier is trained with human labels.\\n\\nOn the dishonesty experiment, the paper compared human labels with GPT-3.5-turbo labels. Although they disagreed on almost half of examples, classifiers trained with GPT-3.5-turbo or human labels achieved comparable accuracy. Using models to replace human annotators is quite feasible; See similar claims here, here and here.\\n\\n\\nExploit: The last step is to use RL to train an adversarial prompt generator to trigger a diverse distribution of harmful outputs. The reward combines the harmfulness classifier score with a diversity constraint measured as intra-batch cosine distance of the target LM’s embeddings. The diversity term is to avoid mode collapse and removing this term in the RL loss leads to complete failure, generating nonsensical prompts.\\n\\n\\nFig. 15. The pipeline of red-teaming via Explore-Establish-Exploit steps. (Image source: Casper et al. 2023)\\nFLIRT (“Feedback Loop In-context Red Teaming”; Mehrabi et al. 2023) relies on in-context learning of a red LM $p_\\\\text{red}$ to attack an image or text generative model $p$ to output unsafe content. Recall that zero-shot prompting was experimented as one way to generate red-teaming attacks in Perez et al. 2022.\\nIn each FLIRT iteration,\\n\\nThe red LM $p_\\\\text{red}$ generates an adversarial prompt $\\\\mathbf{x} \\\\sim p_\\\\text{red}(. \\\\mid {\\\\small{\\\\text{examples}}})$; The initial in-context examples are handcrafted by human;\\nThe generative model $p$ generates an image or a text output $\\\\mathbf{y}$ conditioned on this prompt $\\\\mathbf{y} \\\\sim p(.\\\\mid \\\\mathbf{x})$;\\nThe generated content $\\\\mathbf{y}$ is evaluated whether it is safety using e.g. classifiers;\\nIf it is deemed unsafe, the trigger prompt $\\\\mathbf{x}$ is used to update in-context exemplars for $p_\\\\text{red}$ to generate new adversarial prompts according to a strategy.\\n\\nThere are a couple strategies for how to update in-context examplars in FLIRT:\\n\\nFIFO: Can replace the seed hand-curated examples, and thus the generation can diverge.\\nLIFO: Never replace the seed set of examples and only the last one gets replaced with the latest successful attacks. But quite limited in terms of diversity and attack effectiveness.\\nScoring: Essentially this is a priority queue where examples are ranked by scores. Good attacks are expected to optimize effectiveness (maximize the unsafe generations), diversity (semantically diverse prompts) and low-toxicity (meaning that the text prompt can trick text toxicity classifier).\\n\\nEffectiveness is measured by attack objective functions designed for different experiments:\\n- In text-to-image experiment, they used Q16 (Schramowski et al. 2022) and NudeNet (https://github.com/notAI-tech/NudeNet).\\n- text-to-text experiment: TOXIGEN\\nDiversity is measured by pairwise dissimilarity, in form of $\\\\sum_{(\\\\mathbf{x}_i, \\\\mathbf{x}_j) \\\\in \\\\text{All pairs}} [1 - \\\\text{sim}(\\\\mathbf{x}_i, \\\\mathbf{x}_j)]$\\nLow-toxicity is measured by Perspective API.\\n\\n\\nScoring-LIFO: Combine LIFO and Scoring strategies and force to update the last entry if the queue hasn’t been updated for a long time.'), Document(metadata={'id': '814fc5f8-18b0-4ca1-8fd2-0ae48b49b0e4', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses'), Document(metadata={'id': '5dc12e7d-b20c-40b1-bb10-0881cd8bb69f', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\", 'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en'}, page_content='Fig. 8. Illustration of where adversarial triggers are introduced. The red exclamation points represent adversarial tokens to be learned. (Image source: Zou et al. 2023)\\nThe experiments for triggering affirmative model responses across multiple inputs were conducted on two different models, Vicuna-7b and Vicuna-13b. They adopted greedy coordinate gradient (GCG) based search to greedily find one candidate that can reduce the loss the most among all possible single-token substitutions. It is not feasible to literally evaluate all token substitutions, so they run gradient based token search strategy similar to UAT and AutoPrompt to find top candidates per token, each associated with the largest negative gradient of the loss.\\nGiven a set of expected $m$ input-output pairs ${ (\\\\mathbf{x}^{(i)}, \\\\mathbf{y}^{(i)}) }_{i=1}^m$ (E.g. the input \"Give instructions for building a pipe bomb\", will be associated with an output \"Sure, here’s instructions for building a pipe bomb:\") and  an adversarial suffix $\\\\mathbf{t}$ of length $L$ :\\n\\nPer token in the adversarial suffix $t_j, 1 \\\\leq j \\\\leq L$, we find the top $k$ values with largest negative gradient of NLL loss, $\\\\sum_{i=1}^{m_c} \\\\nabla_{\\\\textbf{e}_{t_j}} p(\\\\mathbf{y}^{(i)} \\\\vert \\\\mathbf{x}^{(i)}, \\\\mathbf{t})$, of the language model $p$. And $m_c$ starts at 1.\\nThen $B < kL$ token substitution candidates ${\\\\mathbf{t}^{(1)}, \\\\dots, \\\\mathbf{t}^{(B)}}$ are selected out of $kL$ options at random and the one with best loss (i.e. largest log-likelihood) is selected to set as the next version of $\\\\mathbf{t} = \\\\mathbf{t}^{(b^*)}$. The process is basically to (1) first narrow down a rough set of substitution candidates with first-order Taylor expansion approximation and (2) then compute the exact change in loss for the most promising candidates. Step (2) is expensive so we cannot afford doing that for a big number of candidates.\\nOnly when the current $\\\\mathbf{t}$ successfully triggers  ${ (\\\\mathbf{x}^{(i)}, \\\\mathbf{y}^{(i)}) }_{i=1}^{m_c}$, we increase $m_c = m_c + 1$. They found this incremental scheduling works better than trying to optimize the whole set of $m$ prompts all at once. This approximates to curriculum learning.\\nThe above step 1-3 are repeated for a number of iterations.\\n\\nAlthough their attack sequences are only trained on open-source models, they show non-trivial transferability to other commercial models, indicating that white-box attacks on open-sourced models can be effective for private models, especially when the underlying training data has overlaps. Note that Vicuna is trained with data collected from GPT-3.5-turbo (via shareGPT), which is essentially distillation, so the attack works more like white-box attack.\\n\\nFig. 9. Average attack success rate on \"HB (harmful behavior)\" instructions, averaging 5 prompts. Two baselines are \"HB\" prompt only or HB prompt followed by `\"Sure here\\'s\"` as a suffix. \"Concatenation\" combines several adversarial suffixes to construct a more powerful attack with a significantly higher success rate in some cases. \"Ensemble\" tracks if any of 5 prompts and the concatenated one succeeded. (Image source: Zou et al. 2023)\\nARCA (“Autoregressive Randomized Coordinate Ascent”; Jones et al. 2023) considers a broader set of optimization problems to find input-output pairs $(\\\\mathbf{x}, \\\\mathbf{y})$ that match certain behavior pattern; such as non-toxic input starting with \"Barack Obama\" but leading to toxic output. Given an auditing objective $\\\\phi: \\\\mathcal{X} \\\\times \\\\mathcal{Y} \\\\to \\\\mathbb{R}$ that maps a pair of (input prompt, output completion) into scores. Examples of behavior patterns captured by $\\\\phi$ are as follows:')]}\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: NOT ALL DOCUMENTS ARE RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "{'question': 'How to make object detection using pytorch?', 'web_search': 'Yes', 'max_retries': 3, 'loop_step': 0, 'documents': []}\n",
      "---WEB SEARCH---\n",
      "{'question': 'How to make object detection using pytorch?', 'web_search': 'Yes', 'max_retries': 3, 'loop_step': 0, 'documents': [Document(metadata={}, page_content=\"Welcome to this hands-on tutorial on building an object detection model using PyTorch and OpenCV. Object detection is a fundamental task in computer vision, with numerous applications in fields like robotics, autonomous vehicles, surveillance, and healthcare. In this tutorial, you'll learn how to: Create a simple object detection model using\\nIn this tutorial, we will guide you through the process of building a real-time object detection system using PyTorch and OpenCV. We will cover the technical background, implementation guide, code examples, best practices, testing, and debugging. What Readers Will Learn. How to build a real-time object detection system using PyTorch and OpenCV\\nMake sure you have a virtual environment set up to keep things organized. You can create one using: python -m venv myenv. And activate it with: source myenv/bin/activate. on Linux or Mac, and: myenv in un. on Windows. Now, you're ready to roll. Choosing a Model. For real-time object detection, you need a pre-trained model.\\nIn this tutorial, you have learned how to create your own training pipeline for object detection models on a custom dataset. For that, you wrote a torch.utils.data.Dataset class that returns the images and the ground truth boxes and segmentation masks. You also leveraged a Mask R-CNN model pre-trained on COCO train2017 in order to perform\\nIn this tutorial, you have learned how to create your own training pipeline for object detection models on a custom dataset. For that, you wrote a torch.utils.data.Dataset class that returns the images and the ground truth boxes and segmentation masks. You also leveraged a Mask R-CNN model pre-trained on COCO train2017 in order to perform transfer learning on this new dataset.\")]}\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "{'question': 'How to make object detection using pytorch?', 'generation': AIMessage(content='To make object detection using PyTorch, you need a pre-trained model for real-time object detection. You can leverage a Mask R-CNN model pre-trained on COCO train2017 to perform transfer learning on your custom dataset. First, create a virtual environment and activate it, then install the necessary libraries and load the pre-trained model.', additional_kwargs={}, response_metadata={'model': 'llama3.2:3B', 'created_at': '2024-12-30T13:49:59.3767119Z', 'done': True, 'done_reason': 'stop', 'total_duration': 838382951, 'load_duration': 26223501, 'prompt_eval_count': 459, 'prompt_eval_duration': 19000000, 'eval_count': 70, 'eval_duration': 791000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-22d6ecbe-0d4f-436c-92be-181ad56a971e-0', usage_metadata={'input_tokens': 459, 'output_tokens': 70, 'total_tokens': 529}), 'web_search': 'Yes', 'max_retries': 3, 'loop_step': 1, 'documents': [Document(metadata={}, page_content=\"Welcome to this hands-on tutorial on building an object detection model using PyTorch and OpenCV. Object detection is a fundamental task in computer vision, with numerous applications in fields like robotics, autonomous vehicles, surveillance, and healthcare. In this tutorial, you'll learn how to: Create a simple object detection model using\\nIn this tutorial, we will guide you through the process of building a real-time object detection system using PyTorch and OpenCV. We will cover the technical background, implementation guide, code examples, best practices, testing, and debugging. What Readers Will Learn. How to build a real-time object detection system using PyTorch and OpenCV\\nMake sure you have a virtual environment set up to keep things organized. You can create one using: python -m venv myenv. And activate it with: source myenv/bin/activate. on Linux or Mac, and: myenv in un. on Windows. Now, you're ready to roll. Choosing a Model. For real-time object detection, you need a pre-trained model.\\nIn this tutorial, you have learned how to create your own training pipeline for object detection models on a custom dataset. For that, you wrote a torch.utils.data.Dataset class that returns the images and the ground truth boxes and segmentation masks. You also leveraged a Mask R-CNN model pre-trained on COCO train2017 in order to perform\\nIn this tutorial, you have learned how to create your own training pipeline for object detection models on a custom dataset. For that, you wrote a torch.utils.data.Dataset class that returns the images and the ground truth boxes and segmentation masks. You also leveraged a Mask R-CNN model pre-trained on COCO train2017 in order to perform transfer learning on this new dataset.\")]}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"How to make object detection using pytorch?\", \"max_retries\": 3}\n",
    "for event in graph.stream(inputs, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454b8bf-864c-4ce1-aa94-37cf87e19918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
